data(olive)
olive = olive[,-1]
data(olive)
olive = olive[,-1]
newData = data.frame(Palmitic = 1200, Palmitoleic = 120, Stearic=200,Oleic=7000,Linoleic = 900, Linolenic = 32, Arachidic=60,Eicosenoic=6)
library(tree)
install.packages("~/Downloads/tree_1.0-34.tar", repos = NULL)
library("tree", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
names(olive)
tree1 <- tree(Area,data=olive)
View(olive)
data(olive)
#olive = olive[,-1]
tree1 <- tree(Area ~ ,data=olive)
tree1 <- tree(Area ~ olive ,data=olive)
data(olive)
tree1 <- tree(Area ~ olive[,-1] ,data=olive)
tree1 <- tree(Area ~ Palmitic ,data=olive)
tree1 <- tree(Area ~ Palmitic + Stearic  ,data=olive)
tree1 <- tree(Area ~ Palmitic + Stearic + Stearic + Oleic + Linoleic + Arachidic + Eicosenoic  ,data=olive)
plot(tree1)
text(tree1)
v <- vector("numeric",length=10)
v
y <- c(TRUE,2)
y
g <- c("a",TRUE)
g
x <- 0:6
x
class(x)
as.numeric(x)
as.logical(x)
as.character(x)
as.complex(x)
m <- matrix(ncol=3,nrow=2)
m
dim(m)
attributes(m)
m <- matrix(1:6,ncol=2,nrow=3)
m
m <- 1:10
dim(m) <- c(2,5)
m
x <- 1:3
y <- 5:7
z <- cbind(x,y)
z
zz <- rbind(x,y)
zz
x <- list(1,"bbtoo",TRUE,1 + 3i)
x
x <- factor(c("yes","no","no","yes"))
x
table(x)
unclass(x)
x
attr(,"levels")
cube <- function(x,n){
x^3
}
cube(3)
pow <- function(x = 4, n = 3) {
x^n
}
pow()
x <- 1:10
if(x > 5){
x <- 0
}
library(datasets)
data(iris)
?iris
iris$Sepal
iris$Sepal.Length
mean(iris$Sepal.Length)
head(iris)
colMeans(iris)
colMeans(iris)
colMeans(iris, na.rm = TRUE)
irisData <- iris[1:4,]
irisData
irisData <- iris[2:*,]
irisData <- iris[2:end,]
size(iris)
dim(iris)
irisData <- iris[2:150,]
head(irisData)
colMeans(iris[,1:5])
iris[,1:5]
iris[,1:4]
colMeans(,iris[,1:4])
iris[,1:4]
head(iris[,1:4])
colMeans(iris[,1])
iris[,1]
colMeans(iris[,1])
rowMeans(iris[,1])
rowMeans(iris[,1:2])
colMeans(iris[,1:2])
colMeans(iris[,1:4])
colMeans(iris[,1:5])
apply(iris,1,mean)
apply(iris,2,mean)
apply(iris,1,mean)
apply(iris[,1:4],2,mean)
apply(iris[,1:4],1,mean)
data(mtcars)
head(mtcars)
head(mtcars)
tapply(mtcars$cyl,mtcars$mpg,mean)
tapply(mtcars$mpg,mtcars$cyl,mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
head(mtcars)
sapply(split(mtcars$hp, mtcars$cyl), mean)
v <- sapply(split(mtcars$hp, mtcars$cyl), mean)
v
v[1]
v[3] - v[1]
library(ggplot2)
install.packages("~/Downloads/ggplot2_0.9.3.1.tar", repos = NULL)
library(ggplot2)
library(digest)
install.packages("~/Downloads/digest_0.6.4.tar", repos = NULL)
library(digest)
library(ggplot2)
install.packages("~/Downloads/gtable_0.1.2.tar", repos = NULL)
library(ggplot2)
install.packages("~/Downloads/plyr_1.8.tar", repos = NULL)
libary(plyr)
library(plyr)
library(ggplot2)
install.packages("~/Downloads/proto_0.3-10.tar", repos = NULL)
library(proto)
library(ggplot2)
library("gtable", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
install.packages("~/Downloads/reshape2_1.2.2.tar", repos = NULL)
library("reshape2", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
install.packages("~/Downloads/stringr_0.6.2.tar", repos = NULL)
library("stringr", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library(ggplot2)
install.packages(ggplot2)
install.packages("ggplot2")
library(ggplot2)
head(maacs[,1:3])
testdat <- data.frame(x =1:100, y = rnorm(100))
testdat[50,2] <- 100
plot(testdat$x, testdat$y, type = "1", ylin = c(-3,3))
plot(testdat$x, testdat$y, type = "1", ylim = c(-3,3))
plot(testdat$x, testdat$y, type = "l", ylim = c(-3,3))
g <- ggplot(testdat, aes(x=x, y=y))
g + geom_line()
cutpoints <- quantile(maacs$logno2_new, seq(0,1,length  4), na.rm = TRUE)
rnorm(0)
rnorm(1)
pnorm(0)
pnorm(1)
pnorm(2.28)
pnorm(2.28) - pnorm(-2.28)
1 - .977392
qnorm(0)
qnorm(1)
qnorm(.5)
?qnorm
1 - pnorm(2.28)
p = .02
mu = .02
var = sqrt((.02*.98)/400)
var
p = .03
std = (.03 - .02)/.007
1 - pnorm(std)
std = (0.03 - .00125 - .02)/.007
std
1 - pnorm(std)
clear all
clc
clear
Clear
clear(mu)
n = 200
p = .46
u = p
var = sqrt(p*(1-p)/n)
var
.04/var
pnorm(.04/var)
1 - pnorm(.04/var)
x = 12 - 1.645*0.4
x
x1 <- c(140,138,150,148,135)
x2 <- c(138,136,148,146,133)
mean(x1)
mean(x2)
var(x1)
var(x2)
s1 <- sqrt(var(x1))
s1
s2 = s1
4/6.49
1 - pnorm(.6163328)
Xnew <- c(0.929,-1.745,1.6770,0.7010,0.128)
Xold <- c(2.233,-2.513,1.204,1.938,2.533)
Xdif <- Xnew - Xold
Xdif
s <- sqrt(var(Xdif))
s
n = 5
u = mean(Xdiff)
u <- mean(Xdif)
u
z <- u/(s/sqrt(5))
z
2*pnorm(-abs(z))
z <- u/(s/sqrt(4))
z
2*pnorm(-abs(z))
sqrt(1.645*4)
(1.645*4)^2
z <- sqrt(288)/6
z
zn <- 1.645 - z
zn
pnorm(zn)
1-pnorm(zn)
exit
quit
x = matrix(data=c(1,2,3,4),nrow=2,ncol-2)
x = matrix(data=c(1,2,3,4),nrow=2,ncol=2)
x
sqrt(x)
x = rnorm(5)
y = x + rnorm(50,mean=50,sd=.1)
cor(x,y)
x = rnorm(50)
y = x + rnorm(50,mean=50,sd=.1)
cor(x,y)
fix(Boston)
rm(Boston)
?fix
fix(Boston)
rm(Boston)
names(Boston)
library(MASS)
library(ISLR)
names(Boston)
lm.fit(medv~lstat)
lm.fit=lm(medv~lstat)
attach(Boston)
lm.fit = lm(medv~lstat)
lm.fit
summary(lm.fit)
names(lm.fit)
coef(lm.fit)
confint(lm.fit)
predict( lm.fit, data.frame( lstat =( c( 5,10,15))),               interval =" confidence")
predict( lm.fit, data.frame( lstat =( c( 5,10,15))),interval ="confidence")
plot(lstat,medv)
abline(lm.fit)
summary(lm.fit)
install.packages("car")
source('~/Documents/Machine Learning/Intro to Statistical Learning/dev/sl8_Trees.R')
tree.carseats
set.seed(2)
train=sample(1:nrow(Carseats),200)
Carseats.test=Carseats[-train,]
High.test=High[-train]
tree.carseats=tree(High~.-Sales,Carseats,subset=train)
tree.pred=predict(tree.carseats,Carseats.test,type="class")
table(tree.pred,High.test)
set.seed(3)
cv.carseats = cv.tree(tree.carseats,FUN=prune.misclass)
names(cv.carseats)
cv.carseats
plot(cv.carseats)
cv.carseats
$size
plot(cv.carseats$size,cv.carseats$dev,type="b")
plot(cv.carseats$k,cv.carseats$dev,type="b")
prune.carseats = prune.misclass(tree.carseats,best=9)
plot(prune.carseats)
text(prune.carsets,pretty=0)
text(prune.carsets,pretty=0)
text(prune.carsets,pretty=O)
text(prune.carseats,pretty=0)
tree.pred=predict(prune.carseats,Carseats.test,type="class")
table(tree.pred,High.test)
install.packages("caret")
library(caret); library(kernlab); data(spam);
install.packages("kernlab")
library(caret); library(kernlab); data(spam);
inTrain <- createdataPartition(y=spam$type, p=0.75,list=FALSE);
inTrain <- createDataPartition(y=spam$type, p=0.75,list=FALSE);
training <-spam[inTrain,]
testing <-spam[-inTrain,]
dim(training)
set.seed(32323)
folds <-createFolds(y=spam$type,k=10,list=TRUE,returnTrain-TRUE)
folds <-createFolds(y=spam$type,k=10,list=TRUE,returnTrain=TRUE)
sapply(folds,length)
folds[[1]]
folds[[1]][1:20]
folds[[2]][1:10]
folds[[10]][1:10]
folds[[20]][1:10]
folds[[2]]
folds[[3]]
folds[[6]]
folds[[8]]
set.seed(32323)
folds <- createResample(y=spam$type,times=10,list=TRUE)
sapply(folds,length)
install.packages("ISLR")
library(ISLR); library(ggplot2);library(caret);
data(Wage)
summary(Wage)
inTrain <- creatDataPartition(y=Wage$wage,p=0.7,list=FALSE)
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training); dim(testing)
featurePlot(x=training[,c("age","education","jobclass")],y=training$Wage,plot="pairs")
featurePlot(x=training[,c("age","education","jobclass")],y=training$Wage,plot="pairs")
featurePlot(x=training[,c("age","education","jobclass")],y=training$wage,plot="pairs")
qplot(age,wage,data=traing)
qplot(age,wage,data=training)
qplot(age,wage,colour=jobclass,data=training)
qq <- qplot(age,wage,colour=education,data=training)
qq + geom_smooth(method='lm',formula=y~x)
library(caret);library(kernlab);data(spam)
inTrain <- createDataPartition(y=spam$type, p=0.75,list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
M <- abs(cor(training[,-58]))
diag(M) <- 0
which(M > 0.8,arr.ind=T)
names(spam)[c(34,32)]
plot(spam[,34],spam[,32])
plot(spam[,40],spam[,32])
plot(spam[,40],spam[,32])
plot(spam[,40],spam[,34])
prComp <- precomp(smallSpam)
smallSpam <- spam[,c(34,32)]
prComp <- precomp(smallSpam)
prComp <- prcomp(smallSpam)
plot(prComp$x[,1],prComp$x[,2])
prComp$rotation
smallSpam <- spam[,c(40,32)]
prComp <- prcomp(smallSpam)
plot(prComp$x[,1],prComp$x[,2])
prComp$rotation
plot(prComp$x[,1],prComp$x[,2],col=typeColor,xlab="PC1",ylab="PC2")
typeColor <- ((spam$type=="spam")*1 + 1)
prComp <- prcomp(log10(spam[,-58]+1))
plot(prComp$x[,1],prComp$x[,2],col=typeColor,xlab="PC1",ylab="PC2")
preProc <- preProcess(log10(spam[,-58]+1,method="pca",pcaComp=2)
spamPC <- predict(preProc,log10(spam[,-58]+1))
preProc <- preProcess(log10(spam[,-58]+1,method="pca",pcaComp=2)
spamPC <- predict(preProc,log10(spam[,-58]+1))
preProc <- preProcess(log10(spam[,-58]+1),method="pca",pcaComp=2)
spamPC <- predict(preProc,log10(spam[,-58]+1))
plot(spamPC[,1],spamPC[,2],col=typeColor)
preProc <- preProcess(log10(training[,58]+1),method="pca",pcaComp=2)
preProc <- preProcess(log10(training[,58]+1),method="pca",pcaComp=2)
preProc <- preProcess(log10(training[,-58]+1),method="pca",pcaComp=2)
trainPC <- predict(preProc,log10(training[,-58]+1))
modelFit <- train(training$type ~ .,method="glm",data=trainPC)
install.packages("e1071")
modelFit <- train(training$type ~ .,method="glm",data=trainPC)
modelFit <- train(training$type ~ .,method="glm",data=trainPC)
testPC <- predict(preProc,log10(testing[,-58]+1))
confusionMatrix(testing$type,predict(modelFit,testPC))
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
names(mixtures)
plot(mixtures$CompressiveStrength)
head(mixtures,10)
hist(mixtures$CompressiveStrength)
head(training,10)
hist(training$CompressiveStrength)
library(Hmisc)
install.packages("Hmisc")
plot(training$CompressiveStrength,training$FlyAsh)
plot(training$FlyAsh, training$CompressiveStrength)
set.seed(1)
x <- runif(1000, 0, 100)
z <- cut2(x, c(10,20,30))
library(Hmisc)
# example in doc
set.seed(1)
x <- runif(1000, 0, 100)
z <- cut2(x, c(10,20,30))
table(z)
table(cut2(x, g=10)) # quantile groups
table(cut2(x, m=50)) # group x into intevals with at least 50 obs.
class(z)
z
hist(training$FlyAsh)
training$flyAshF <- cut2(training$FlyAsh,g=6)
plot(training$CompressiveStrength, col=training$flyAshF)
plot(training$CompressiveStrength)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
names(mixtures)
plot(training$CompressiveStrength)
head(training,10)
hist(training$CompressiveStrength)
M <- abs(cor(training[,-58]))
diag(M) <- 0
which(M > 0.8,arr.ind=T)
which(M > 0.5,arr.ind=T)
which(M > 0.3,arr.ind=T)
M
plot(training$cement,training$CompressiveStrength)
plot(training$Cement,training$CompressiveStrength)
plot(training$Cement)
hist(training$Superplasticizer)
min(c(2,3))
min(training$Superplasticizer)
hist(log10(training$Superplasticizer))
hist(log10(training$Superplasticizer)+5)
hist(log10(training$Superplasticizer)+4)
hist(log10(training$Superplasticizer + 1))
plot(training$Superplasticizer)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
?plot.enet
install.packages("plot.enet")
?elasticnet
install.packages("elasticnet")
?plot.enet
?elasticnet
library("elasticnet", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
?elasticnet
?plot.enet
?enet
x <- 1:100
y <- 2*x - 1
y2 <- x + 10
par(mfrow=c(1,2))
plot(x,y)
plot(x,y2)
x <- 1:100
y <- 2*x - 1
y2 <- sqrt(x) + 10
par(mfrow=c(1,2))
plot(x,y)
plot(x,y2)
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
View(testing)
View(adData)
View(testing)
View(predictors)
setwd("~/Documents/coursera/Data Science/Data Products/project/rocproject")
deployApp()
library(shinyapps)
library(shiny)
publishApp()
deployApp()
library(devtools)
deployApp()
devtools::install_github('rstudio/shinyapps')
deployApp()
library("tools", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
deployApp()
library(shinyapps)
deployApp()
setAccountInfo()
shinyapps::setAccountInfo(name='rbjorkdataproduct', token='3B56427FE25FDCFD5CA78F537AF13500', secret='gaWyluziD9L13jlZm2aRTDSrJprUSzvlBHjYXqtO')
deployApp()
ls
dir
setwd("~/Documents/coursera/Data Science/Data Products/project/rocproject/deploy")
shinyapps::setAccountInfo(name='rbjorkdataproduct', token='3B56427FE25FDCFD5CA78F537AF13500', secret='gaWyluziD9L13jlZm2aRTDSrJprUSzvlBHjYXqtO')
deployApp()
install.packages("RcppEigen")
deployApp()
runApp()
getwd()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shinyapps::setAccountInfo(name='rbjorkdataproduct', token='3B56427FE25FDCFD5CA78F537AF13500', secret='gaWyluziD9L13jlZm2aRTDSrJprUSzvlBHjYXqtO')
deployApp()
